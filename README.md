# [TreeFormers - An Exploration of Vision Transformers for Deforestation Driver Classification](https://drive.google.com/file/d/1DaKIpjEsVMnta3KCT1RgXnaenUtGrnTU/view?usp=drive_link)
## Uche Ochuba
uochuba@cs.stanford.edu \
Stanford University Department of Computer Science \
Computer Science 229: Machine Learning 




This repository contains the code written and used for the TreeFormers paper. This project involved employing vision transformer (ViT) architectures for image classification. I worked on creating various models to classify a dataset of over 2,750 satellite images of Indonesia by the deforestation driver.

**data_loaders** - various scripts used to load, modify, and format data for training transformers.

**lr_baseline** - interactive Python notebook containing code written to establish a logistic regression baseline, based on research from online and course materials.

**pre_trained_transformers** - contains engine code used to train and test pre-trained, fine-tuned vision transformers.

**scratch_transformer** - contains code adapted from Meta Platforms that was done in an attempt to train ViT from scratch.
